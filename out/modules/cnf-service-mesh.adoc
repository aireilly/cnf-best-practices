// Metadata created by nebel
//
// ConvertedFromFile: cnf-reqs_1.3_single.adoc
// ConversionStatus: raw

[id="cnf-service-mesh"]
= Service Mesh for Inter/Intra NF

.Service Mesh Introduction

Kubernetes clusters have a network with flat layer 3 IP connectivity between all pods, provided by a pluggable layer in Kubernetes called the Container Network Interface (CNI). In the basic deployment scenario, that means that any application container can communicate with any other application container and any details of that communication (plaintext or encryption, what protocols, authentication, monitoring) are the responsibility of each application container. Without intervention, each application is forced to implement all aspects of security requiring a high degree of effort and diligence. Much of this effort is replicated since each application must repeat it. As an example, even if all applications implement TLS properly, when a vulnerability is discovered in a TLS implementation, every individual application must have a separate vulnerability analysis executed, and patches made to software code and updated in the field. A modern approach to securing traffic between Kubernetes pods (and thus, the containerized applications that run in them such as CNFs and MEC apps): is a service mesh. The service mesh is a security-enhancing sidecar container that runs in each pod and proxies network traffic from or to the main application container. In its position as a proxy, the service mesh sidecar can provide security, resiliency, load balancing, and detailed measurement for the application container. Importantly, the sidecar provides a consistent implementation of each of these functions regardless of the details of the application. For example, the sidecar has one implementation of TLS that is used for all sidecars across the entire Kubernetes cluster - if a vulnerability in this implementation is found, only one upgrade must be performed. The sidecar is transparently injected into the Kubernetes pod without requiring any intervention by the main application container.

Application containers do not need to communicate in any special way with the sidecar directly. Generally, application containers should be unaware of the presence of the sidecar; they communicate "as normal" and the sidecar transparently proxies these communications as long as they are allowed by policy. This document details the requirements so that the sidecar can correctly proxy application traffic and apply policy.

Service Mesh is also capable of doing CSR generation, signing and installation into the namespace as part of the solution. This offloads all PKI efforts from the CNF and also makes the certificates available for NFs within the application via kubernetes secrets as a volume mount should an application require the keys for doing any TLS via Multus based interfaces.

Additionally Service Mesh allows distributed tracing for HTTP based flows that can be analyzed via the Jaeger UI. This provides a consistent visibility mechanism across NFs for Service Based Interface (SBI) based communication.

The following diagram depicts Service Mesh at a high level.

_Service Mesh High Level Overview_

image:./images/media/image2.png[./images/media/image2,width=624,height=609]

_Service Mesh Detailed View_

image:./images/media/image3.png[./images/media/image3,width=417,height=556]

This diagram depicts the full suite of components that are involved with Service Mesh delivery. Pilot is the Istio Control plane, the sidecar proxies are Envoy based proxies. Trace collector and prometheus provide statistics and traces. Not depicted is Jaeger which allows viewing of traces.

.Service Mesh Tapping

Because of Service Mesh's unique location related to the HTTP traffic for SBI interfaces, it is well positioned to provide a tapping solution to feed tools for doing traces on network traffic for the purposes of call traces and evaluating overall network health via statistical analysis. Because Service Mesh is able to front end all SBI interfaces, it provides the capacity for comprehensive and consistent visibility across all of the SBI interfaces within the 5G Core.

.Service Mesh Requirements for CNF

. The application MUST declare all listening ports as containerPorts in the Pod specification it provides to Kubernetes.
.. The application MUST NOT listen on any other ports that are undeclared.
.. The service mesh MAY be configured to block connections to these ports.
.. These ports MUST be named in the pod specification with the protocol they implement.
... The name field in the ContainerPort section must be of the form <protocol>[-<suffix>] where <protocol> is one of the below, and the optional <suffix> can be chosen by the application.
... Preferred prefixes: grpc , grpc-web , http , http2
... Fallback prefixes: tcp , udp
... Valid Example: http-webapi or grpc
. The application MUST communicate with Kubernetes Services by their service IP instead of selecting Pods in that service individually.
.. The service mesh will select the appropriate pod.
. The application MUST NOT encrypt outbound traffic on the cluster network interface.
.. The service mesh will apply policy, authenticate servers and encrypt outbound traffic before it leaves the application pod.
. The application MUST NOT decrypt inbound traffic on the cluster network interface.
.. The service mesh will decrypt, authenticate clients and apply policy before redirecting traffic to the application container.
. The application SHOULD NOT manage certificates related to communication over the cluster network interface.
.. The service mesh will manage, rotate and validate these certificates.
. The application MUST NOT provide nftables or iptables rules.
. The application MUST NOT use UID 1337 or tcp ports 15001, 15020.
. The application MUST NOT define Kubernetes Custom Resources in these namespaces:
.. \*.istio.io
.. \*.aspenmesh.io
. The application MUST NOT define Kubernetes resources in the istio-system namespace.
. The application MUST propagate tracing headers when making outgoing requests based on incoming requests.
.. Example: If an application receives a request with a trace header identifying that request with traceid 785a908c8d93b2d2 , and decides based on application logic that it must make a new request to another application pod to fulfill that request, it must annotate the new request with the same traceid 785a908c8d93b2d2.
.. The application MUST propagate all of these tracing headers if present: x-request-id, x-b3-traceid, x-b3-spanId, x-b3-parentspanid, x-b3-sampled, x-b3-flags, b3
.. The application MUST propagate the tracing headers by copying any header value from the original request to the new request.
.. The application SHOULD NOT modify any of these header values unless it understands the format of the headers and wishes to enhance them (e.g. implements OpenTracing)
.. If some or none of the headers are present, the application SHOULD NOT create them.
.. If an application makes a new request and it is not in service of exactly one incoming request, it MAY omit all tracing headers.
... Note: The application does not have to generate headers in this case. It could generate headers if it implements e.g. OpenTracing, and the service mesh would use and propagate those IDs. This is optional.
... If there are no tracing headers, the service mesh will generate a new trace.

